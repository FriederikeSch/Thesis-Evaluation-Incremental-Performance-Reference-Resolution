{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook calculates general incremental performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "from collections import Counter\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(model,mode, dataset, split,full=True):\n",
    "#load predicted and gold bounding boxes\n",
    "\n",
    "    try:\n",
    "        if full==False:\n",
    "            with open(r\"/home/users/fschreiber/project/bboxes_empty_\"+model+\"/\"+dataset+\"/\"+split+\"_pred_bbox_list.p\",\"rb\") as f:\n",
    "                pred_bbox_list=list(pickle.load(f)) \n",
    "\n",
    "            #the target bounding box\n",
    "            with open(r\"/home/users/fschreiber/project/bboxes_empty_\"+model+\"/\"+dataset+\"/\"+split+\"_target_bbox_list.p\",\"rb\") as f:\n",
    "                target_bbox_list=list(pickle.load(f))   \n",
    "        else:\n",
    "            #the predicted bounding box\n",
    "            with open(r\"/home/users/fschreiber/project/bboxes_\"+model+\"/\"+dataset+\"/\"+split+\"_pred_bbox_list.p\",\"rb\") as f:\n",
    "                pred_bbox_list=list(pickle.load(f))\n",
    "\n",
    "            if mode==\"non_inc\":\n",
    "                #the target bounding box\n",
    "                with open(r\"/home/users/fschreiber/project/bboxes_noninc_\"+model+\"/\"+dataset+\"/\"+split+\"_pred_bbox_list.p\",\"rb\") as f:\n",
    "                    target_bbox_list=list(pickle.load(f))\n",
    "\n",
    "            elif mode == \"inc\":\n",
    "                #the target bounding box\n",
    "                with open(r\"/home/users/fschreiber/project/bboxes_\"+model+\"/\"+dataset+\"/\"+split+\"_target_bbox_list.p\",\"rb\") as f:\n",
    "                    target_bbox_list=list(pickle.load(f))\n",
    "            else:\n",
    "                print(\"The mode can only be non_inc or inc\")\n",
    "                return -1,-1,-1,-1,-1\n",
    "\n",
    "        #the number of one sentence split up incrementally (\"the left zebra\" would have length 3)\n",
    "        with open(r\"/home/users/fschreiber/project/incremental_pickles/length_incremental_units/\"+dataset+\"_\"+split+\"_length_unit.p\",\"rb\") as f:\n",
    "            inc_len=pickle.load(f)\n",
    "\n",
    "        #the original model data split up incrementally\n",
    "        data_model=torch.load(\"/home/users/fschreiber/project/ready_inc_data/\"+dataset+\"/\"+dataset+\"_\"+split+\".pth\")\n",
    "\n",
    "        with open(r\"/home/users/fschreiber/project/binary_grouped/\"+model+\"/\"+mode+\"/\"+dataset+split+\".p\",\"rb\") as f:\n",
    "            binary_grouped=pickle.load(f)\n",
    "\n",
    "        \n",
    "        if mode==\"non_inc\":\n",
    "            target_bbox_list=[x for x,y in zip(target_bbox_list,inc_len) for _ in range(y)]\n",
    "\n",
    "        if full==False:\n",
    "            pred_bbox_list=[x for x,y in zip(pred_bbox_list,inc_len) for _ in range(y)]\n",
    "            target_bbox_list=[x for x,y in zip(target_bbox_list,inc_len) for _ in range(y)]\n",
    "\n",
    "        if model==\"TVG\":\n",
    "            pred_bbox_list,target_bbox_list=TVG_prep(pred_bbox_list,target_bbox_list)\n",
    "                    \n",
    "\n",
    "        return pred_bbox_list,target_bbox_list,inc_len,data_model,binary_grouped\n",
    "    \n",
    "    except FileNotFoundError as e:\n",
    "        #print(e)\n",
    "        \n",
    "        return  -1,-1,-1,-1,-1\n",
    "    \n",
    "\n",
    "\n",
    "#TVG needs some extra adjustments to fit the same data format as Resc\n",
    "def TVG_prep(pred_bbox_list,target_bbox_list):\n",
    "    #print(\"TVG\")\n",
    "    for ind,(pred,targ) in enumerate (zip (pred_bbox_list,target_bbox_list)):\n",
    "\n",
    "        pred=pred.view(1,-1)\n",
    "\n",
    "        pred=xywh2xyxy(pred)\n",
    "        pred=torch.clamp(pred,0,1)\n",
    "\n",
    "        pred_bbox_list[ind]=pred\n",
    "\n",
    "        targ=targ.view(1,-1)\n",
    "        targ=xywh2xyxy(targ)\n",
    "\n",
    "        target_bbox_list[ind]=targ\n",
    "    return pred_bbox_list,target_bbox_list\n",
    "\n",
    "#copied from TransVG needed to transform the bounding box vectors\n",
    "def xywh2xyxy(x):\n",
    "    x_c, y_c, w, h = x.unbind(-1)\n",
    "    b = [(x_c - 0.5 * w), (y_c - 0.5 * h),\n",
    "         (x_c + 0.5 * w), (y_c + 0.5 * h)]\n",
    "    return torch.stack(b, dim=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_bbox_list,target_bbox_list,inc_len,model,binary_grouped=load_data(\"ReSc\",\"inc\",\"unc\",\"testB\",False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#copied from ReSC\n",
    "def bbox_iou(box1, box2, x1y1x2y2=True):\n",
    "    \"\"\"\n",
    "    Returns the IoU of two bounding boxes\n",
    "    \"\"\"\n",
    "    if x1y1x2y2:\n",
    "        # Get the coordinates of bounding boxes\n",
    "        b1_x1, b1_y1, b1_x2, b1_y2 = box1[:, 0], box1[:, 1], box1[:, 2], box1[:, 3]\n",
    "        b2_x1, b2_y1, b2_x2, b2_y2 = box2[:, 0], box2[:, 1], box2[:, 2], box2[:, 3]\n",
    "    else:\n",
    "        # Transform from center and width to exact coordinates\n",
    "        b1_x1, b1_x2 = box1[:, 0] - box1[:, 2] / 2, box1[:, 0] + box1[:, 2] / 2\n",
    "        b1_y1, b1_y2 = box1[:, 1] - box1[:, 3] / 2, box1[:, 1] + box1[:, 3] / 2\n",
    "        b2_x1, b2_x2 = box2[:, 0] - box2[:, 2] / 2, box2[:, 0] + box2[:, 2] / 2\n",
    "        b2_y1, b2_y2 = box2[:, 1] - box2[:, 3] / 2, box2[:, 1] + box2[:, 3] / 2\n",
    "\n",
    "    # get the coordinates of the intersection rectangle\n",
    "    inter_rect_x1 = torch.max(b1_x1, b2_x1)\n",
    "\n",
    "    #print(\"inter x1\",inter_rect_x1)\n",
    "\n",
    "    inter_rect_y1 = torch.max(b1_y1, b2_y1)\n",
    "\n",
    "    #print(\"inter y1\",inter_rect_y1)\n",
    "\n",
    "    inter_rect_x2 = torch.min(b1_x2, b2_x2)\n",
    "\n",
    "    #print(\"inter x2\",inter_rect_x2)\n",
    "\n",
    "    inter_rect_y2 = torch.min(b1_y2, b2_y2)\n",
    "\n",
    "    #print(\"inter y2\",inter_rect_y2)\n",
    "\n",
    "    #print(\"x2-x1\",inter_rect_x2-inter_rect_x1)\n",
    "\n",
    "    #print(\"y2-y1\",inter_rect_y2-inter_rect_y1)\n",
    "\n",
    "    # Intersection area\n",
    "    inter_area = torch.clamp(inter_rect_x2 - inter_rect_x1, 0) * torch.clamp(inter_rect_y2 - inter_rect_y1, 0)\n",
    "    # Union Area\n",
    "    b1_area = (b1_x2 - b1_x1) * (b1_y2 - b1_y1)\n",
    "    b2_area = (b2_x2 - b2_x1) * (b2_y2 - b2_y1)\n",
    "\n",
    "    # print(box1, box1.shape)\n",
    "    # print(box2, box2.shape)\n",
    "\n",
    "    #print(\"inter area\",inter_area)\n",
    "    return inter_area / (b1_area + b2_area - inter_area + 1e-16)\n",
    "    #return inter_area / (b1_area + b2_area - inter_area + 1e-16),inter_rect_x2-inter_rect_x1,inter_rect_y2-inter_rect_y1\n",
    "\n",
    "\n",
    "#copied from TransVG needed to transform the bounding box vectors\n",
    "def xywh2xyxy(x):\n",
    "    x_c, y_c, w, h = x.unbind(-1)\n",
    "    b = [(x_c - 0.5 * w), (y_c - 0.5 * h),\n",
    "         (x_c + 0.5 * w), (y_c + 0.5 * h)]\n",
    "    return torch.stack(b, dim=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#group sentences that belong to one incremental unit\n",
    "def group_by_increment(bbox_list,inc_len):\n",
    "    counter=0\n",
    "    group_list=[]\n",
    "    for i in inc_len:\n",
    "        \n",
    "        group_list.append(bbox_list[counter:counter+i])\n",
    "        counter=counter+i\n",
    "    return group_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2931183726466133\n"
     ]
    }
   ],
   "source": [
    "#gives the overall accuracy\n",
    "acc_list=[]\n",
    "for i,j in zip(pred_bbox_list,target_bbox_list):\n",
    "    acc_list.append(bbox_iou(i,j,True))\n",
    "\n",
    "percentage = sum(1 for item in acc_list if item > 0.5) / len(acc_list)\n",
    "print(percentage)\n",
    "\n",
    "#change the percentages into true or false\n",
    "binary_list=[1 if entry > 0.5 else 0 for entry in acc_list]\n",
    "\n",
    "binary_grouped=group_by_increment(binary_list,inc_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#is correct found at the end? final applicable\n",
    "def final_applicable(binary_grouped):\n",
    "    counter=0\n",
    "    for entry in binary_grouped:\n",
    "         \n",
    "        if entry[-1]==1:\n",
    "            counter+=1\n",
    "\n",
    "    return counter/len(binary_grouped)\n",
    "\n",
    "#final_applicable(binary_grouped)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#is the correct object found at all? first applicable\n",
    "def first_applicable(binary_grouped):\n",
    "    counter=0\n",
    "    for entry in binary_grouped:\n",
    "        if 1 in entry:\n",
    "            counter+=1\n",
    "    \n",
    "    return counter/len(binary_grouped)\n",
    "\n",
    "#first_applicable(binary_grouped=binary_grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0, 1631)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#first correct position\n",
    "#find the position where the first correct answer is given \n",
    "def first_correct_position(binary_grouped):\n",
    "    \n",
    "    first_corr_pos=[]\n",
    "    for entry in binary_grouped:\n",
    "\n",
    "        #for every entry with at least one correct guess\n",
    "        if 1 in entry:\n",
    "            #add the index of the first correct guess and stop\n",
    "            for index,number in enumerate(entry):\n",
    "                if number==1:\n",
    "                    \n",
    "                    first_corr_pos.append(index)\n",
    "                    break\n",
    "    \n",
    "    return first_corr_pos\n",
    "\n",
    "first_corr_pos=first_correct_position(binary_grouped)\n",
    "\n",
    "#filter binary list for only answers where the correct answer is reached at least once\n",
    "only_correct=[]\n",
    "for entry in binary_grouped:\n",
    "    if 1 in entry:\n",
    "        only_correct.append(entry)\n",
    "\n",
    "#calculate the percentage of the sentence where fc is found\n",
    "#and the absolute position\n",
    "perc_first_correct_pos=[]\n",
    "for entry,pos in zip(only_correct, first_corr_pos):\n",
    "    \n",
    "    perc_first_correct_pos.append( pos/len(entry))\n",
    "\n",
    "average_first_correct_rel=sum(perc_first_correct_pos)/len(perc_first_correct_pos)\n",
    "average_first_correct_pos=sum(first_corr_pos)/len(first_corr_pos)\n",
    "\n",
    "print(average_first_correct_rel)\n",
    "print(average_first_correct_pos)\n",
    "\n",
    "\n",
    "c=Counter(first_corr_pos)\n",
    "c.most_common()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average first final 0.0\n"
     ]
    }
   ],
   "source": [
    "#find first final position\n",
    "def find_unchanged_position(numbers_list):\n",
    "    for index, number in enumerate(numbers_list):\n",
    "        if number == 1 and all(num == 1 for num in numbers_list[index:]):\n",
    "             \n",
    "            return index , index/len(numbers_list)\n",
    "    \n",
    "    #if no position is found    \n",
    "    return -1,-1 \n",
    "\n",
    "\n",
    "def first_final_position(binary_grouped):\n",
    "    \n",
    "    #get results as the absolute position and the position relative to the sentence length\n",
    "    first_final_pos=[]\n",
    "    first_final_pos_rel=[]\n",
    "    for entry in binary_grouped:\n",
    "            index,rel_pos =find_unchanged_position(entry)\n",
    "            first_final_pos.append(index)\n",
    "            first_final_pos_rel.append(rel_pos)\n",
    "\n",
    "    #remove all -1 from list\n",
    "    first_final_pos = [num for num in first_final_pos if num != -1]\n",
    "    first_final_pos_rel = [num for num in first_final_pos_rel if num != -1]\n",
    "    \n",
    "    return first_final_pos,first_final_pos_rel\n",
    "\n",
    "\n",
    "first_final_pos, first_final_pos_rel= first_final_position(binary_grouped)\n",
    "\n",
    "average_first_final= sum(first_final_pos_rel)/len(first_final_pos_rel)\n",
    "print(\"Average first final\",average_first_final)\n",
    "#c=Counter(first_final_pos)\n",
    "#c.most_common()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#the function tries to determine if the predicted target boxes reference the same object\\n#the prediction boxes are compared to each other if their overlap is bigger than 0.5 it is assumed \\n#that they describe the same object\\n\\ndef find_same_object(pred_bbox_list):\\n    \\n    #first we assume that every entry in the predictions describes a unique object\\n    #therefore it gets a unique index number\\n    same_list=list(range(len(pred_bbox_list)))\\n    \\n    #compare each entry to each other\\n    for ind_sm, value_sm in enumerate(pred_bbox_list):\\n        \\n        for ind_lg , value_lg in enumerate(pred_bbox_list):\\n            \\n            #if the index of the later entry is smaller or same as the earlier entry \\n            # this entry was already seen in an earlier loop and can be skipped \\n            if same_list[ind_lg] > same_list[ind_sm]:\\n\\n                #if the bounding boxes of the two entries compared overlap\\n                #the index number of the later entry is changed to the earliest occurrence\\n                if bbox_iou(value_sm,value_lg)>0.5:\\n                    same_list[ind_lg]=same_list[ind_sm]\\n    \\n    \\n\\n\\n    #change the index position in the script to be strictly ascending\\n    \\n    unique_list=[]\\n    #the number of unique objects\\n    obj_c=0\\n    \\n    #list to match the index position to a unqiue object number\\n    #the first entry is the old index position\\n    #the second entry is the new unique object count\\n    match_list=[(int(0),int(0))]\\n    \\n    for num in same_list:\\n        \\n        #when the index position is not in match list\\n        #it gets added to the list with a new object number\\n        if num > match_list[-1][0]:\\n            \\n            obj_c+=1\\n            match_list.append((num,obj_c))\\n            \\n            unique_list.append(obj_c)\\n\\n        #when the number was seen before \\n        # add the object number matching the index position to the new list\\n        else:\\n            result = next((item[1] for item in match_list if item[0] == num), None)\\n            \\n            if result==None:  \\n                print(\"Number:\",num,\"was not found in list. This should not happen\")\\n            else:\\n                \\n                unique_list.append(result)\\n                \\n    return unique_list\\n\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#the function tries to determine if the predicted target boxes reference the same object\n",
    "#the prediction boxes are compared to each other if their overlap is bigger than 0.5 it is assumed \n",
    "#that they describe the same object\n",
    "\n",
    "def find_same_object(pred_bbox_list):\n",
    "    \n",
    "    #first we assume that every entry in the predictions describes a unique object\n",
    "    #therefore it gets a unique index number\n",
    "    same_list=list(range(len(pred_bbox_list)))\n",
    "    \n",
    "    #compare each entry to each other\n",
    "    for ind_sm, value_sm in enumerate(pred_bbox_list):\n",
    "        \n",
    "        for ind_lg , value_lg in enumerate(pred_bbox_list):\n",
    "            \n",
    "            #if the index of the later entry is smaller or same as the earlier entry \n",
    "            # this entry was already seen in an earlier loop and can be skipped \n",
    "            if same_list[ind_lg] > same_list[ind_sm]:\n",
    "\n",
    "                #if the bounding boxes of the two entries compared overlap\n",
    "                #the index number of the later entry is changed to the earliest occurrence\n",
    "                if bbox_iou(value_sm,value_lg)>0.5:\n",
    "                    same_list[ind_lg]=same_list[ind_sm]\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    #change the index position in the script to be strictly ascending\n",
    "    \n",
    "    unique_list=[]\n",
    "    #the number of unique objects\n",
    "    obj_c=0\n",
    "    \n",
    "    #list to match the index position to a unqiue object number\n",
    "    #the first entry is the old index position\n",
    "    #the second entry is the new unique object count\n",
    "    match_list=[(int(0),int(0))]\n",
    "    \n",
    "    for num in same_list:\n",
    "        \n",
    "        #when the index position is not in match list\n",
    "        #it gets added to the list with a new object number\n",
    "        if num > match_list[-1][0]:\n",
    "            \n",
    "            obj_c+=1\n",
    "            match_list.append((num,obj_c))\n",
    "            \n",
    "            unique_list.append(obj_c)\n",
    "\n",
    "        #when the number was seen before \n",
    "        # add the object number matching the index position to the new list\n",
    "        else:\n",
    "            result = next((item[1] for item in match_list if item[0] == num), None)\n",
    "            \n",
    "            if result==None:  \n",
    "                print(\"Number:\",num,\"was not found in list. This should not happen\")\n",
    "            else:\n",
    "                \n",
    "                unique_list.append(result)\n",
    "                \n",
    "    return unique_list\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate correctness\n",
    "def correctness(binary_grouped):\n",
    "    count_list=[]\n",
    "\n",
    "    for entry in binary_grouped:\n",
    "        count_list.append(entry.count(1)/len(entry))\n",
    "\n",
    "    average_correctness=sum(count_list)/len(count_list)\n",
    "    #print(average_correctness)\n",
    "    \n",
    "    return average_correctness\n",
    "\n",
    "#correctness(binary_grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates the mean edits per utterance\n",
    "def mean_edits_per_utterance(binary_grouped):\n",
    "    \n",
    "    # Initialize two empty lists to store the positions of first correct (fc) with and without a final (ff) in each entry\n",
    "    fc_no_final = []  # fc without a final\n",
    "    fc_ed_utt = []    # fc with a final\n",
    "\n",
    "    # Loop through each entry in the binary_grouped data\n",
    "    for entry in binary_grouped:\n",
    "        \n",
    "        # For every entry where a first final is found\n",
    "        if entry[-1] == 1:\n",
    "            # Find the position of the first '1' in the entry, which represents a first correct\n",
    "            for index, number in enumerate(entry):\n",
    "                if number == 1:\n",
    "                    fc_ed_utt.append(index)\n",
    "                    break\n",
    "        \n",
    "        # For every entry where the first correct is found but the first final is not\n",
    "        # Take the length to the end\n",
    "        else:\n",
    "            if 1 in entry:\n",
    "                # Find the position of the first '1' (first correct) in the entry\n",
    "                for index, number in enumerate(entry):\n",
    "                    if number == 1:\n",
    "                        fc_no_final.append(len(entry) - index - 1)\n",
    "                        break\n",
    "\n",
    "    # Create an empty list to store the differences between first final position and first correct position\n",
    "    diff_ed_ut = []\n",
    "\n",
    "    # Get the positions of the first final and first correct in each entry using a helper function 'first_final_position'\n",
    "    first_final_pos, _ = first_final_position(binary_grouped)\n",
    "\n",
    "    # Calculate the difference between first final and first correct positions for entries with a final\n",
    "    for fc, ff in zip(fc_ed_utt, first_final_pos):\n",
    "        diff_ed_ut.append(ff - fc)\n",
    "\n",
    "    # Combine the differences for entries with and without a final\n",
    "    diff_ed_ut = diff_ed_ut + fc_no_final\n",
    "\n",
    "    # Calculate the average of the differences, which represents the mean edits per utterance\n",
    "    return sum(diff_ed_ut) / len(diff_ed_ut)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unctestB\n",
      "unctestA\n",
      "uncval\n",
      "unc+testB\n",
      "unc+testA\n",
      "unc+val\n",
      "gref_umdval\n",
      "gref_umdtest\n",
      "grefval\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Percentage</th>\n",
       "      <th>Position</th>\n",
       "      <th>Applicable</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dataset First CorrectReSc inc</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>unc testB</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unc testA</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unc val</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unc+ testB</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unc+ testA</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unc+ val</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gref_umd val</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gref_umd test</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gref val</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Percentage  Position  Applicable\n",
       "Dataset First CorrectReSc inc                                  \n",
       "unc testB                             0.0       0.0        0.32\n",
       "unc testA                             0.0       0.0        0.32\n",
       "unc val                               0.0       0.0        0.32\n",
       "unc+ testB                            0.0       0.0        0.15\n",
       "unc+ testA                            0.0       0.0        0.13\n",
       "unc+ val                              0.0       0.0        0.14\n",
       "gref_umd val                          0.0       0.0        0.35\n",
       "gref_umd test                         0.0       0.0        0.35\n",
       "gref val                              0.0       0.0        0.18"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Percentage</th>\n",
       "      <th>Position</th>\n",
       "      <th>Applicable</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dataset First Final ReSc inc</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>unc testB</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unc testA</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unc val</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unc+ testB</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unc+ testA</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unc+ val</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gref_umd val</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gref_umd test</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gref val</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Percentage  Position  Applicable\n",
       "Dataset First Final ReSc inc                                  \n",
       "unc testB                            0.0       0.0        0.32\n",
       "unc testA                            0.0       0.0        0.32\n",
       "unc val                              0.0       0.0        0.32\n",
       "unc+ testB                           0.0       0.0        0.15\n",
       "unc+ testA                           0.0       0.0        0.13\n",
       "unc+ val                             0.0       0.0        0.14\n",
       "gref_umd val                         0.0       0.0        0.35\n",
       "gref_umd test                        0.0       0.0        0.35\n",
       "gref val                             0.0       0.0        0.18"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Edits per Utterance</th>\n",
       "      <th>Correctness</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Non Incremental Accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dataset Edits ReSc inc</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>unc testB</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.29</td>\n",
       "      <td>71.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unc testA</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.29</td>\n",
       "      <td>78.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unc val</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.29</td>\n",
       "      <td>76.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unc+ testB</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.13</td>\n",
       "      <td>56.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unc+ testA</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.13</td>\n",
       "      <td>65.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unc+ val</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.12</td>\n",
       "      <td>63.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gref_umd val</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.35</td>\n",
       "      <td>64.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gref_umd test</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.34</td>\n",
       "      <td>64.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gref val</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.19</td>\n",
       "      <td>61.16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Edits per Utterance  Correctness  Accuracy  \\\n",
       "Dataset Edits ReSc inc                                               \n",
       "unc testB                               0.0         0.32      0.29   \n",
       "unc testA                               0.0         0.32      0.29   \n",
       "unc val                                 0.0         0.32      0.29   \n",
       "unc+ testB                              0.0         0.15      0.13   \n",
       "unc+ testA                              0.0         0.13      0.13   \n",
       "unc+ val                                0.0         0.14      0.12   \n",
       "gref_umd val                            0.0         0.35      0.35   \n",
       "gref_umd test                           0.0         0.35      0.34   \n",
       "gref val                                0.0         0.18      0.19   \n",
       "\n",
       "                        Non Incremental Accuracy  \n",
       "Dataset Edits ReSc inc                            \n",
       "unc testB                                  71.85  \n",
       "unc testA                                  78.61  \n",
       "unc val                                    76.74  \n",
       "unc+ testB                                 56.08  \n",
       "unc+ testA                                 65.94  \n",
       "unc+ val                                   63.21  \n",
       "gref_umd val                               64.89  \n",
       "gref_umd test                              64.01  \n",
       "gref val                                   61.16  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#load data\n",
    "\n",
    "found_sets_list,accuracy_list,fcp_list,fc_rel_list,fca_list, \\\n",
    "ffp_list,ff_rel_list,ffa_list,ed_utt_list, \\\n",
    "overhead_list,correctness_list,ffc_pos_list=([] for i in range(12))\n",
    "\n",
    "mode=\"inc\"\n",
    "model_input=\"ReSc\"\n",
    "split_list=[\"testB\",\"testA\",\"val\",\"test\"]\n",
    "dataset_list=[\"unc\",\"unc+\",\"gref_umd\",\"gref\"]\n",
    "#dataset_list=[\"unc\"]\n",
    "\n",
    "non_inc_acc_Resc=[71.85, 78.61, 76.74, 56.08, 65.94, 63.21, 64.89, 64.01,61.16]\n",
    "non_inc_acc_TVG=[76.9, 83.4, 80.8, 59.2, 72.5, 68.0, 68.7, 68.0, 68.0]\n",
    "\n",
    "\n",
    "for file in dataset_list:\n",
    "    for split in split_list:\n",
    "    \n",
    "        pred_bbox_list,target_bbox_list,inc_len,model,binary_grouped= load_data(model_input,mode,file,split,False)\n",
    "\n",
    "        #if the file is not found pass\n",
    "        if pred_bbox_list==-1 or target_bbox_list==-1 or inc_len==-1:\n",
    "             pass\n",
    "\n",
    "        else:\n",
    "\n",
    "            print(file+split)\n",
    "            found_sets_list.append(file+\" \"+split)\n",
    "            \n",
    "            #calculate the overall accuracy\n",
    "            acc_list=[]\n",
    "            for i,j in zip(pred_bbox_list,target_bbox_list):\n",
    "                acc_list.append(bbox_iou(i,j,True))\n",
    "\n",
    "            accuracy_list.append(sum(1 for item in acc_list if item > 0.5) / len(acc_list))\n",
    "            \n",
    "            #change the percentages into true or false\n",
    "            binary_list=[1 if entry > 0.5 else 0 for entry in acc_list]\n",
    "\n",
    "            binary_grouped=group_by_increment(binary_list,inc_len)\n",
    "            \n",
    "\n",
    "            #get the metrics\n",
    "            \n",
    "            #first correct position\n",
    "            first_corr_pos=first_correct_position(binary_grouped)\n",
    "            ffc_pos_list.append(Counter(first_corr_pos))\n",
    "           \n",
    "            #filter binary list for only answers where the correct answer is reached at least once\n",
    "            only_correct=[]\n",
    "            for entry in binary_grouped:\n",
    "                if 1 in entry:\n",
    "                    only_correct.append(entry)\n",
    "            \n",
    "            #get relative and absolute first correct position\n",
    "            perc_first_correct_pos=[]\n",
    "            for entry,pos in zip(only_correct, first_corr_pos):\n",
    "                \n",
    "                perc_first_correct_pos.append( pos/len(entry))\n",
    "\n",
    "            average_first_correct_perc=sum(perc_first_correct_pos)/len(perc_first_correct_pos)\n",
    "            average_first_correct_pos=sum(first_corr_pos)/len(first_corr_pos)\n",
    "            #print(average_first_correct)\n",
    "            fcp_list.append(average_first_correct_pos)\n",
    "            fc_rel_list.append(average_first_correct_perc)\n",
    "            \n",
    "\n",
    "            #first correct applicable\n",
    "            fca_list.append(first_applicable(binary_grouped))\n",
    "\n",
    "            #first final position\n",
    "            first_final_pos,first_final_pos_rel=first_final_position(binary_grouped)\n",
    "            \n",
    "            average_first_final_pos= sum(first_final_pos)/len(first_final_pos)\n",
    "            average_first_final_rel= sum(first_final_pos_rel)/len(first_final_pos_rel)\n",
    "            \n",
    "            ffp_list.append(average_first_final_pos)\n",
    "            ff_rel_list.append(average_first_final_rel)\n",
    "\n",
    "            #first final aplicable\n",
    "            ffa_list.append(final_applicable(binary_grouped))\n",
    "\n",
    "            #mean edits per utterance\n",
    "            ed_utt_list.append(mean_edits_per_utterance(binary_grouped))\n",
    "\n",
    "            #correctness\n",
    "            correctness_list.append(correctness(binary_grouped))\n",
    "\n",
    "#Create dataframes\n",
    "data_fc={}\n",
    "\n",
    "data_fc[\"Dataset First Correct\"+model_input+\" \"+mode]=found_sets_list\n",
    "data_fc[\"Percentage\"]=fc_rel_list\n",
    "data_fc[\"Position\"]=fcp_list\n",
    "data_fc[\"Applicable\"]=fca_list\n",
    "\n",
    "df_fc = pd.DataFrame(data_fc)\n",
    "if mode==\"non_inc\":\n",
    "    df_fc[\"Percentage\"]= df_fc[\"Percentage\"].round(2)\n",
    "    df_fc[\"Position\"]= df_fc[\"Position\"].round(2)\n",
    "    \n",
    "elif mode==\"inc\":\n",
    "    df_fc=df_fc.round(2)\n",
    "    \n",
    "else: \n",
    "    print(\"Mode can only be inc or non_inc. Mode is:\",mode)\n",
    "\n",
    "df_fc.set_index(\"Dataset First Correct\"+model_input+\" \"+mode,inplace=True)\n",
    "display(df_fc)\n",
    "\n",
    "\n",
    "data_ff={}\n",
    "data_ff[\"Dataset First Final \"+model_input+\" \"+mode]=found_sets_list\n",
    "data_ff[\"Percentage\"]=ff_rel_list\n",
    "data_ff[\"Position\"]=ffp_list\n",
    "data_ff[\"Applicable\"]=ffa_list\n",
    "\n",
    "\n",
    "df_ff=pd.DataFrame(data_ff)\n",
    "if mode==\"non_inc\":\n",
    "    df_ff[\"Percentage\"]= df_ff[\"Percentage\"].round(2)\n",
    "    df_ff[\"Position\"]= df_ff[\"Position\"].round(2)\n",
    "\n",
    "elif mode==\"inc\":\n",
    "    df_ff=df_ff.round(2)\n",
    "    \n",
    "else: \n",
    "    print(\"Mode can only be inc or non_inc. Mode is:\",mode)\n",
    "\n",
    "df_ff.set_index(\"Dataset First Final \"+model_input+\" \"+mode,inplace=True)\n",
    "display(df_ff)\n",
    "\n",
    "data_edit={}\n",
    "data_edit[\"Dataset Edits \"+model_input+\" \"+mode]=found_sets_list\n",
    "data_edit[\"Edits per Utterance\"]=ed_utt_list\n",
    "data_edit[\"Correctness\"]=correctness_list\n",
    "data_edit[\"Accuracy\"]=accuracy_list\n",
    "\n",
    "if model_input==\"ReSc\":\n",
    "    data_edit[\"Non Incremental Accuracy\"]=non_inc_acc_Resc\n",
    "\n",
    "elif model_input==\"TVG\":\n",
    "    data_edit[\"Non Incremental Accuracy\"]=non_inc_acc_TVG\n",
    "else:\n",
    "    print(\"Model Input can only be ReSc or TVG not:\",model_input)\n",
    "\n",
    "df_edit=pd.DataFrame(data_edit)\n",
    "\n",
    "\n",
    "if mode==\"non_inc\":\n",
    "    df_edit[\"Edits per Utterance\"]= df_edit[\"Edits per Utterance\"].round(2)\n",
    "    df_edit[\"Correctness\"]= df_edit[\"Correctness\"].round(2)\n",
    "    df_edit[\"Accuracy\"]= df_edit[\"Accuracy\"].round(2)\n",
    "    df_edit[\"Non Incremental Accuracy\"]= df_edit[\"Non Incremental Accuracy\"].round(2)\n",
    "\n",
    "elif mode==\"inc\":\n",
    "    df_edit=df_edit.round(2)\n",
    "    \n",
    "else: \n",
    "    print(\"Mode can only be inc or non_inc. Mode is:\",mode)\n",
    "\n",
    "df_edit.set_index(\"Dataset Edits \"+model_input+\" \"+mode,inplace=True)\n",
    "display(df_edit)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "simrec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
