{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook calculates the distribution of completly correct, wrong and mixed examples and the sentence length in the datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(model,mode, dataset, split):\n",
    "#load predicted and gold bounding boxes\n",
    "        \n",
    "    try:\n",
    "\n",
    "        #the predicted bounding box\n",
    "        with open(r\"/home/users/fschreiber/project/bboxes_\"+model+\"/\"+dataset+\"/\"+split+\"_pred_bbox_list.p\",\"rb\") as f:\n",
    "            pred_bbox_list=list(pickle.load(f))\n",
    "\n",
    "        if mode==\"non_inc\":\n",
    "            #the target bounding box\n",
    "            with open(r\"/home/users/fschreiber/project/bboxes_noninc_\"+model+\"/\"+dataset+\"/\"+split+\"_pred_bbox_list.p\",\"rb\") as f:\n",
    "                target_bbox_list=list(pickle.load(f))\n",
    "\n",
    "        elif mode == \"inc\":\n",
    "            #the target bounding box\n",
    "            with open(r\"/home/users/fschreiber/project/bboxes_\"+model+\"/\"+dataset+\"/\"+split+\"_target_bbox_list.p\",\"rb\") as f:\n",
    "                target_bbox_list=list(pickle.load(f))\n",
    "        else:\n",
    "            print(\"The mode can only be non_inc or inc\")\n",
    "            return -1,-1,-1,-1,-1\n",
    "\n",
    "        #the number of one sentence split up incrementally (\"the left zebra\" would have length 3)\n",
    "        with open(r\"/home/users/fschreiber/project/incremental_pickles/length_incremental_units/\"+dataset+\"_\"+split+\"_length_unit.p\",\"rb\") as f:\n",
    "            inc_len=pickle.load(f)\n",
    "\n",
    "        #the original model data split up incrementally\n",
    "        data_model=torch.load(\"/home/users/fschreiber/project/ready_inc_data/\"+dataset+\"/\"+dataset+\"_\"+split+\".pth\")\n",
    "\n",
    "        #information if the object was found or not grouped by sentence\n",
    "        with open(r\"/home/users/fschreiber/project/binary_grouped/\"+model+\"/\"+mode+\"/\"+dataset+split+\".p\",\"rb\") as f:\n",
    "            binary_grouped=pickle.load(f)\n",
    "\n",
    "        #if non_inc the targetboxes need to be filed up to the complete length\n",
    "        if mode==\"non_inc\":\n",
    "            target_bbox_list=[x for x,y in zip(target_bbox_list,inc_len) for _ in range(y)]\n",
    "            \n",
    "        if model==\"TVG\":\n",
    "            pred_bbox_list,target_bbox_list=TVG_prep(pred_bbox_list,target_bbox_list)\n",
    "        return pred_bbox_list,target_bbox_list,inc_len,data_model,binary_grouped\n",
    "    \n",
    "    except FileNotFoundError as e:\n",
    "        #print(e)\n",
    "        \n",
    "        return  -1,-1,-1,-1,-1\n",
    "    \n",
    "\n",
    "#TVG needs some extra adjustments to fit the same data format as Resc\n",
    "def TVG_prep(pred_bbox_list,target_bbox_list):\n",
    "    #print(\"TVG\")\n",
    "    for ind,(pred,targ) in enumerate (zip (pred_bbox_list,target_bbox_list)):\n",
    "\n",
    "        pred=pred.view(1,-1)\n",
    "\n",
    "        pred=xywh2xyxy(pred)\n",
    "        pred=torch.clamp(pred,0,1)\n",
    "\n",
    "        pred_bbox_list[ind]=pred\n",
    "\n",
    "        targ=targ.view(1,-1)\n",
    "        targ=xywh2xyxy(targ)\n",
    "\n",
    "        target_bbox_list[ind]=targ\n",
    "    return pred_bbox_list,target_bbox_list\n",
    "\n",
    "#copied from TransVG needed to transform the bounding box vectors\n",
    "def xywh2xyxy(x):\n",
    "    x_c, y_c, w, h = x.unbind(-1)\n",
    "    b = [(x_c - 0.5 * w), (y_c - 0.5 * h),\n",
    "         (x_c + 0.5 * w), (y_c + 0.5 * h)]\n",
    "    return torch.stack(b, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_bbox_list,target_bbox_list,inc_len,model,binary_grouped=load_data(\"TVG\",\"inc\",\"unc\",\"testB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#group sentences that belong to one incremental unit\n",
    "def group_by_increment(bbox_list,inc_len):\n",
    "    counter=0\n",
    "    group_list=[]\n",
    "    for i in inc_len:\n",
    "        \n",
    "        group_list.append(bbox_list[counter:counter+i])\n",
    "        counter=counter+i\n",
    "    return group_list\n",
    "\n",
    "\n",
    "pred_group=group_by_increment(pred_bbox_list,inc_len)\n",
    "targ_group=group_by_increment(target_bbox_list,inc_len)\n",
    "model_group=group_by_increment(model,inc_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split up the list into entries where each guess is correct,wrong or mixed save the indices\n",
    "\n",
    "def split_by_correct(binary_grouped):\n",
    "    only_one=[]\n",
    "    only_zero=[]\n",
    "    mixed=[]\n",
    "    #mixed_values=[]\n",
    "\n",
    "    for index,entry in enumerate(binary_grouped):\n",
    "        if all(p == 1 for p in entry):\n",
    "            only_one.append(index)\n",
    "        elif all (p ==0 for p in entry):\n",
    "            only_zero.append(index)\n",
    "        else:\n",
    "            mixed.append(index)\n",
    "            #mixed_values.append(entry)\n",
    "    \n",
    "    return only_one,only_zero,mixed\n",
    "\n",
    "\n",
    "only_one,only_zero,mixed=split_by_correct(binary_grouped)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unctestB\n",
      "unctestA\n",
      "uncval\n",
      "unc+testB\n",
      "unc+testA\n",
      "unc+val\n",
      "gref_umdval\n",
      "gref_umdtest\n",
      "grefval\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Right</th>\n",
       "      <th>Wrong</th>\n",
       "      <th>Mixed</th>\n",
       "      <th>Average Sentence Length</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ReSc</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>unctestB</th>\n",
       "      <td>0.44</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.32</td>\n",
       "      <td>3.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unctestA</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.32</td>\n",
       "      <td>3.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uncval</th>\n",
       "      <td>0.48</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.33</td>\n",
       "      <td>3.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unc+testB</th>\n",
       "      <td>0.36</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.30</td>\n",
       "      <td>3.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unc+testA</th>\n",
       "      <td>0.46</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.29</td>\n",
       "      <td>3.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unc+val</th>\n",
       "      <td>0.42</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.31</td>\n",
       "      <td>3.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gref_umdval</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.53</td>\n",
       "      <td>8.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gref_umdtest</th>\n",
       "      <td>0.24</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.54</td>\n",
       "      <td>8.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grefval</th>\n",
       "      <td>0.19</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.56</td>\n",
       "      <td>8.37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Right  Wrong  Mixed  Average Sentence Length\n",
       "ReSc                                                      \n",
       "unctestB       0.44   0.24   0.32                     3.63\n",
       "unctestA       0.50   0.17   0.32                     3.43\n",
       "uncval         0.48   0.19   0.33                     3.57\n",
       "unc+testB      0.36   0.34   0.30                     3.76\n",
       "unc+testA      0.46   0.25   0.29                     3.34\n",
       "unc+val        0.42   0.28   0.31                     3.59\n",
       "gref_umdval    0.25   0.22   0.53                     8.37\n",
       "gref_umdtest   0.24   0.22   0.54                     8.28\n",
       "grefval        0.19   0.25   0.56                     8.37"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize three empty lists: one_all, zero_all, and mixed_all.\n",
    "one_all, zero_all, mixed_all = ([] for i in range(3))\n",
    "\n",
    "# Define variables for mode, model_input, split_list, and dataset_list.\n",
    "mode = \"inc\"\n",
    "model_input = \"ReSc\"\n",
    "split_list = [\"testB\", \"testA\", \"val\", \"test\"]\n",
    "dataset_list = [\"unc\", \"unc+\", \"gref_umd\", \"gref\"]\n",
    "\n",
    "# Create an empty list to store found dataset splits and sentence lengths.\n",
    "found_sets_list = []\n",
    "sentence_length_list = []\n",
    "\n",
    "# Iterate through each dataset in dataset_list and each split in split_list.\n",
    "for file in dataset_list:\n",
    "    for split in split_list:\n",
    "\n",
    "        # Call the load_data function to load data for the given parameters.\n",
    "        pred_bbox_list, target_bbox_list, inc_len, model, binary_grouped = load_data(model_input, mode, file, split)\n",
    "\n",
    "        # Check if the file is not found and skip to the next iteration.\n",
    "        if pred_bbox_list == -1 or target_bbox_list == -1 or inc_len == -1:\n",
    "            pass\n",
    "        else:\n",
    "            # Print the combination of file and split.\n",
    "            print(file + split)\n",
    "            found_sets_list.append(file + split)\n",
    "\n",
    "            # Split the binary_grouped data into three categories: only_one, only_zero, and mixed.\n",
    "            only_one, only_zero, mixed = split_by_correct(binary_grouped)\n",
    "\n",
    "            # Calculate and append the percentage of each category to one_all, zero_all, and mixed_all.\n",
    "            one_all.append(len(only_one) / len(binary_grouped))\n",
    "            zero_all.append(len(only_zero) / len(binary_grouped))\n",
    "            mixed_all.append(len(mixed) / len(binary_grouped))\n",
    "\n",
    "            # Calculate and append the average sentence length to sentence_length_list.\n",
    "            sentence_length = []\n",
    "            for sent in binary_grouped:\n",
    "                sentence_length.append(len(sent))\n",
    "            sentence_length_list.append(sum(sentence_length) / len(sentence_length))\n",
    "\n",
    "# Create a dictionary to store the collected data.\n",
    "data = {}\n",
    "data[model_input] = found_sets_list\n",
    "\n",
    "# Store the percentages of correct, wrong, and mixed predictions, and average sentence length \n",
    "data[\"Right\"] = one_all\n",
    "data[\"Wrong\"] = zero_all\n",
    "data[\"Mixed\"] = mixed_all\n",
    "data[\"Average Sentence Length\"] = sentence_length_list\n",
    "\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.set_index(model_input, inplace=True)\n",
    "df = df.round(2)\n",
    "\n",
    "df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "simrec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
