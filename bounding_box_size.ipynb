{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook calculates the sizes of predicted and target bounding boxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "from PIL import Image\n",
    "import statistics\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FormatStrFormatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(model,mode, dataset, split):\n",
    "#load predicted and gold bounding boxes\n",
    "        \n",
    "    try:\n",
    "\n",
    "        #the predicted bounding box\n",
    "        with open(r\"/home/users/fschreiber/project/bboxes_\"+model+\"/\"+dataset+\"/\"+split+\"_pred_bbox_list.p\",\"rb\") as f:\n",
    "            pred_bbox_list=list(pickle.load(f))\n",
    "\n",
    "        if mode==\"non_inc\":\n",
    "            #the target bounding box\n",
    "            with open(r\"/home/users/fschreiber/project/bboxes_noninc_\"+model+\"/\"+dataset+\"/\"+split+\"_pred_bbox_list.p\",\"rb\") as f:\n",
    "                target_bbox_list=list(pickle.load(f))\n",
    "\n",
    "        elif mode == \"inc\":\n",
    "            #the target bounding box\n",
    "            with open(r\"/home/users/fschreiber/project/bboxes_\"+model+\"/\"+dataset+\"/\"+split+\"_target_bbox_list.p\",\"rb\") as f:\n",
    "                target_bbox_list=list(pickle.load(f))\n",
    "        else:\n",
    "            print(\"The mode can only be non_inc or inc\")\n",
    "            return -1,-1,-1,-1,-1\n",
    "\n",
    "        #the number of one sentence split up incrementally (\"the left zebra\" would have length 3)\n",
    "        with open(r\"/home/users/fschreiber/project/incremental_pickles/length_incremental_units/\"+dataset+\"_\"+split+\"_length_unit.p\",\"rb\") as f:\n",
    "            inc_len=pickle.load(f)\n",
    "\n",
    "        #the original model data split up incrementally\n",
    "        data_model=torch.load(\"/home/users/fschreiber/project/ready_inc_data/\"+dataset+\"/\"+dataset+\"_\"+split+\".pth\")\n",
    "\n",
    "        with open(r\"/home/users/fschreiber/project/binary_grouped/\"+model+\"/\"+mode+\"/\"+dataset+split+\".p\",\"rb\") as f:\n",
    "            binary_grouped=pickle.load(f)\n",
    "\n",
    "        \n",
    "        if mode==\"non_inc\":\n",
    "            target_bbox_list=[x for x,y in zip(target_bbox_list,inc_len) for _ in range(y)]\n",
    "            \n",
    "        if model==\"TVG\":\n",
    "            #pred_bbox_list,target_bbox_list=TVG_prep(pred_bbox_list,target_bbox_list)\n",
    "\n",
    "            for i in range(len(data_model)):\n",
    "    \n",
    "                path=\"/home/users/fschreiber/project/TransVG/ln_data/other/images/mscoco/images/train2014/\"+data_model[i][0]\n",
    "                image = Image.open(path)\n",
    "                image_width, image_height = image.size\n",
    "                \n",
    "                pred_bbox_list[i]=transform_coordinates(pred_bbox_list[i],image_width,image_height)\n",
    "                target_bbox_list[i]=transform_coordinates(target_bbox_list[i],image_width,image_height)\n",
    "\n",
    "        return pred_bbox_list,target_bbox_list,inc_len,data_model,binary_grouped\n",
    "    \n",
    "    except FileNotFoundError as e:\n",
    "        #print(e)\n",
    "        \n",
    "        return  -1,-1,-1,-1,-1\n",
    "    \n",
    "\n",
    "\n",
    "#TVG needs some extra adjustments to fit the same data format as Resc\n",
    "def TVG_prep(pred_bbox_list,target_bbox_list):\n",
    "    #print(\"TVG\")\n",
    "    for ind,(pred,targ) in enumerate (zip (pred_bbox_list,target_bbox_list)):\n",
    "\n",
    "        pred=pred.view(1,-1)\n",
    "\n",
    "        pred=xywh2xyxy(pred)\n",
    "        pred=torch.clamp(pred,0,1)\n",
    "\n",
    "        pred_bbox_list[ind]=pred\n",
    "\n",
    "        targ=targ.view(1,-1)\n",
    "        targ=xywh2xyxy(targ)\n",
    "\n",
    "        target_bbox_list[ind]=targ\n",
    "    return pred_bbox_list,target_bbox_list\n",
    "\n",
    "#copied from TransVG needed to transform the bounding box vectors\n",
    "def xywh2xyxy(x):\n",
    "    x_c, y_c, w, h = x.unbind(-1)\n",
    "    b = [(x_c - 0.5 * w), (y_c - 0.5 * h),\n",
    "         (x_c + 0.5 * w), (y_c + 0.5 * h)]\n",
    "    return torch.stack(b, dim=-1)\n",
    "\n",
    "\n",
    "\n",
    "#TVG coordinates are normalized between 0 and 1 reshape them to fit the image\n",
    "def transform_coordinates(normalized_coords, image_width, image_height):\n",
    "    # Multiply the normalized coordinates by image size\n",
    "    pixel_coords = normalized_coords * torch.tensor([[image_width, image_height, image_width, image_height]])\n",
    "\n",
    "    return pixel_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_bbox_list,target_bbox_list,inc_len,model,binary_grouped=load_data(\"TVG\",\"inc\",\"unc\",\"testB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#group sentences that belong to one incremental unit\n",
    "def group_by_increment(bbox_list,inc_len):\n",
    "    counter=0\n",
    "    group_list=[]\n",
    "    for i in inc_len:\n",
    "        \n",
    "        group_list.append(bbox_list[counter:counter+i])\n",
    "        counter=counter+i\n",
    "    return group_list\n",
    "\n",
    "\n",
    "pred_group=group_by_increment(pred_bbox_list,inc_len)\n",
    "targ_group=group_by_increment(target_bbox_list,inc_len)\n",
    "model_group=group_by_increment(model,inc_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split up the list into entries where each guess is correct,wrong or mixed save the indices\n",
    "#with one being correct guesses and zero incorrect guesses\n",
    "\n",
    "def split_by_correct(binary_grouped):\n",
    "    only_one=[]\n",
    "    only_zero=[]\n",
    "    mixed=[]\n",
    "\n",
    "    for index,entry in enumerate(binary_grouped):\n",
    "        if all(p == 1 for p in entry):\n",
    "            only_one.append(index)\n",
    "        elif all (p ==0 for p in entry):\n",
    "            only_zero.append(index)\n",
    "        else:\n",
    "            mixed.append(index)\n",
    "    \n",
    "    return only_one,only_zero,mixed\n",
    "\n",
    "\n",
    "only_one,only_zero,mixed=split_by_correct(binary_grouped)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def covered_area(pred_group,ind_list,model_group):\n",
    "\n",
    "    img_area=[]\n",
    "\n",
    "    for i in range(len(pred_group)):\n",
    "        path=\"/home/users/fschreiber/project/TransVG/ln_data/other/images/mscoco/images/train2014/\"+model_group[i][0][0]\n",
    "\n",
    "        image= Image.open(path)\n",
    "\n",
    "        image_width, image_height = image.size\n",
    "\n",
    "        img_area.append(image_width*image_height)\n",
    "\n",
    "    prog=[]\n",
    "    covered_area=[]\n",
    "    \n",
    "    for i in ind_list:\n",
    "                \n",
    "        hold_area=[]\n",
    "        hold_cov=[]\n",
    "\n",
    "\n",
    "        for entry in pred_group[i]:\n",
    "            width = abs((entry[0][0]-entry[0][2]))\n",
    "            height = abs((entry[0][1]-entry[0][3]))\n",
    "            \n",
    "\n",
    "            area_bb=width*height\n",
    "            hold_area.append(area_bb)\n",
    "\n",
    "            cov_perc = (area_bb/ img_area[i]) * 100\n",
    "\n",
    "            hold_cov.append(cov_perc)\n",
    "\n",
    "\n",
    "        prog.append(hold_area)\n",
    "        covered_area.append(hold_cov)\n",
    "\n",
    "    return covered_area\n",
    "\n",
    "cov_area_one=covered_area(pred_group,only_one,model_group)\n",
    "cov_area_zero=covered_area(pred_group,only_zero,model_group)\n",
    "cov_area_mixed=covered_area(pred_group,mixed,model_group)\n",
    "\n",
    "\n",
    "cov_area_all=cov_area_one+cov_area_zero+cov_area_mixed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"The function calculates the area of an image covered by the bounding box to determine its size\n",
    "pred_group is a list of the coordinates of prediction bounding boxes\n",
    "ind_list hold the index of the condition used (right,wrong mixes)\n",
    "model_group holds model information\n",
    "\"\"\"\n",
    "def covered_area(pred_group, ind_list, model_group):\n",
    "\n",
    "    # Create an empty list to store the areas of images.\n",
    "    img_area = []\n",
    "\n",
    "    # Iterate through the prediction coordinates.\n",
    "    for i in range(len(pred_group)):\n",
    "        \n",
    "        # Generate the path to the image file based on the model information.\n",
    "        path = \"/home/users/fschreiber/project/TransVG/ln_data/other/images/mscoco/images/train2014/\" + model_group[i][0][0]\n",
    "\n",
    "        image = Image.open(path)\n",
    "\n",
    "        image_width, image_height = image.size\n",
    "\n",
    "        # Calculate the image size\n",
    "        img_area.append(image_width * image_height)\n",
    "\n",
    "   \n",
    "    prog = []\n",
    "    covered_area = []\n",
    "\n",
    "    #Iterate through each entry in ind_list.\n",
    "    for i in ind_list:\n",
    "        hold_cov = []\n",
    "\n",
    "        # Iterate through the coordinates in pred_group.\n",
    "        for entry in pred_group[i]:\n",
    "           \n",
    "            # Calculate the width and height of the bounding box.\n",
    "            width = abs((entry[0][0] - entry[0][2]))\n",
    "            height = abs((entry[0][1] - entry[0][3]))\n",
    "\n",
    "            # Calculate the area of the bounding box.\n",
    "            area_bb = width * height\n",
    "            hold_area.append(area_bb)\n",
    "\n",
    "            # Calculate the coverage percentage of the bounding box relative to the image.\n",
    "            cov_perc = (area_bb / img_area[i]) * 100\n",
    "            hold_cov.append(cov_perc)\n",
    "\n",
    "        # Append the lists of areas and coverage percentages for this index to prog and covered_area, respectively.\n",
    "        prog.append(hold_area)\n",
    "        covered_area.append(hold_cov)\n",
    "\n",
    "    # Return the list of coverage percentages for all specified indices.\n",
    "    return covered_area\n",
    "\n",
    "\n",
    "cov_area_one = covered_area(pred_group, only_one, model_group)\n",
    "cov_area_zero = covered_area(pred_group, only_zero, model_group)\n",
    "cov_area_mixed = covered_area(pred_group, mixed, model_group)\n",
    "\n",
    "# Combine the coverage percentages from different conditions into a single list.\n",
    "cov_area_all = cov_area_one + cov_area_zero + cov_area_mixed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dist(cov_area_all,dataset,split):\n",
    "    cov_area_all_flat=lst = [item for sublist in cov_area_all for item in sublist]\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    counts, bins, patches = ax.hist(cov_area_all_flat,bins=15, edgecolor='black')\n",
    "    #plt.hist(cov_area_all_flat, density=False, bins=20,edgecolor='black')\n",
    "\n",
    "    plt.xlabel(\"Percentage of image covered by bounding box\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.title(f\"Distribution of bounding box size for the {dataset} {split} dataset\")\n",
    "    ax.set_xticks(bins)\n",
    "    ax.xaxis.set_major_formatter(FormatStrFormatter('%0.0f'))\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot a histogram of bounding box sizes\n",
    "def plot_dist(cov_area_all, dataset, split):\n",
    "    \n",
    "    # Flatten the list with coverage information\n",
    "    cov_area_all_flat = [item for sublist in cov_area_all for item in sublist]\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    counts, bins, patches = ax.hist(cov_area_all_flat, bins=15, edgecolor='black')\n",
    "\n",
    "\n",
    "    #Set labels\n",
    "    plt.xlabel(\"Percentage of image covered by bounding box\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.title(f\"Distribution of bounding box size for the {dataset} {split} dataset\")\n",
    "\n",
    "    ax.set_xticks(bins)\n",
    "    ax.xaxis.set_major_formatter(FormatStrFormatter('%0.0f'))\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "   \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unctestB\n",
      "unctestA\n",
      "uncval\n",
      "unc+testB\n",
      "unc+testA\n",
      "unc+val\n",
      "gref_umdval\n",
      "gref_umdtest\n",
      "grefval\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Right Avg Size</th>\n",
       "      <th>Wrong Avg Size</th>\n",
       "      <th>Mixed Avg Size</th>\n",
       "      <th>All Avg Size</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TVG targ</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>unctestB</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unctestA</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uncval</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unc+testB</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unc+testA</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unc+val</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gref_umdval</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gref_umdtest</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grefval</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Right Avg Size  Wrong Avg Size  Mixed Avg Size  All Avg Size\n",
       "TVG targ                                                                  \n",
       "unctestB                 0.0             0.0             0.0           0.0\n",
       "unctestA                 0.0             0.0             0.0           0.0\n",
       "uncval                   0.0             0.0             0.0           0.0\n",
       "unc+testB                0.0             0.0             0.0           0.0\n",
       "unc+testA                0.0             0.0             0.0           0.0\n",
       "unc+val                  0.0             0.0             0.0           0.0\n",
       "gref_umdval              0.0             0.0             0.0           0.0\n",
       "gref_umdtest             0.0             0.0             0.0           0.0\n",
       "grefval                  0.0             0.0             0.0           0.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "one_sum,one_std,zero_sum,zero_std,mixed_sum,mixed_std,all_sum,all_std=([] for i in range(8))\n",
    "\n",
    "box_mode=\"targ\"\n",
    "mode=\"inc\"\n",
    "model_input=\"TVG\"\n",
    "split_list=[\"testB\",\"testA\",\"val\",\"test\"]\n",
    "dataset_list=[\"unc\",\"unc+\",\"gref_umd\",\"gref\"]\n",
    "#dataset_list=[\"unc\"]\n",
    "found_sets_list=[]\n",
    "\n",
    "for file in dataset_list:\n",
    "    for split in split_list:\n",
    "        \n",
    "        pred_bbox_list,target_bbox_list,inc_len,model,binary_grouped=load_data(model_input,mode,file,split)\n",
    "\n",
    "        #if the file is not found pass\n",
    "        if pred_bbox_list==-1 or target_bbox_list==-1 or inc_len==-1:\n",
    "                pass\n",
    "    \n",
    "\n",
    "        else:\n",
    "            print(file+split)\n",
    "            found_sets_list.append(file+split)\n",
    "\n",
    "            pred_group=group_by_increment(pred_bbox_list,inc_len)\n",
    "            targ_group=group_by_increment(target_bbox_list,inc_len)\n",
    "            model_group=group_by_increment(model,inc_len)\n",
    "\n",
    "            only_one,only_zero,mixed=split_by_correct(binary_grouped)\n",
    "\n",
    "\n",
    "            if box_mode==\"pred\":\n",
    "                cov_area_one=(covered_area(pred_group,only_one,model_group))\n",
    "                cov_area_zero=(covered_area(pred_group,only_zero,model_group))\n",
    "                cov_area_mixed=(covered_area(pred_group,mixed,model_group))\n",
    "            \n",
    "            elif box_mode==\"targ\":\n",
    "                cov_area_one=(covered_area(targ_group,only_one,model_group))\n",
    "                cov_area_zero=(covered_area(targ_group,only_zero,model_group))\n",
    "                cov_area_mixed=(covered_area(targ_group,mixed,model_group))\n",
    "\n",
    "            else: \n",
    "                print(\"Box Mode must be either pred or targ. It is:\",box_mode)\n",
    "                break\n",
    "                \n",
    "            cov_area_all=cov_area_one+cov_area_zero+cov_area_mixed\n",
    "\n",
    "            #plot_dist(cov_area_all,file,split)\n",
    "            \n",
    "            cov_list=[cov_area_one,cov_area_zero,cov_area_mixed,cov_area_all]\n",
    "            cov_type=[\"Right\",\"Wrong\",\"Mixed\",\"All\"]\n",
    "\n",
    "            for lst,type in zip(cov_list,cov_type):\n",
    "                \n",
    "                lst = [item for sublist in lst for item in sublist]\n",
    "                lst = [tensor.tolist() for tensor in lst]\n",
    "\n",
    "                if type==\"Right\":\n",
    "                    one_sum.append(round(sum(lst)/len(lst),2))\n",
    "                    one_std.append(round(statistics.stdev(lst),2))\n",
    "                elif type==\"Wrong\":\n",
    "                    zero_sum.append(round(sum(lst)/len(lst),2))\n",
    "                    zero_std.append(round(statistics.stdev(lst),2))\n",
    "                elif type==\"Mixed\":\n",
    "                    mixed_sum.append(round(sum(lst)/len(lst),2))\n",
    "                    mixed_std.append(round(statistics.stdev(lst),2))\n",
    "                elif type==\"All\":\n",
    "                    all_sum.append(round(sum(lst)/len(lst),2))\n",
    "                    all_std.append(round(statistics.stdev(lst),2))\n",
    "\n",
    "\n",
    "data={}\n",
    "\n",
    "data[model_input+\" \"+box_mode]=found_sets_list\n",
    "data[\"Right Avg Size\"]=one_sum\n",
    "#data[\"Right Standard Deviation\"]=one_std\n",
    "\n",
    "data[\"Wrong Avg Size\"]=zero_sum\n",
    "#data[\"Wrong Standard Deviation\"]=zero_std\n",
    "\n",
    "data[\"Mixed Avg Size\"]=mixed_sum\n",
    "#data[\"Mixed Standard Deviation\"]=mixed_std\n",
    "\n",
    "data[\"All Avg Size\"]=all_sum\n",
    "#data[\"All Standard Deviation\"]=all_std\n",
    "\n",
    "\n",
    "df=pd.DataFrame(data)\n",
    "\n",
    "df.set_index(model_input+\" \"+box_mode,inplace=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "one_sum, one_std, zero_sum, zero_std, mixed_sum, mixed_std, all_sum, all_std = ([] for i in range(8))\n",
    "\n",
    "# Define configuration parameters.\n",
    "box_mode = \"targ\"  # 'targ' mode indicates using target bounding boxes\n",
    "mode = \"inc\"\n",
    "model_input = \"TVG\"\n",
    "split_list = [\"testB\", \"testA\", \"val\", \"test\"]\n",
    "dataset_list = [\"unc\", \"unc+\", \"gref_umd\", \"gref\"]\n",
    "#dataset_list = [\"unc\"]  \n",
    "\n",
    "found_sets_list = []  \n",
    "\n",
    "# Iterate over datasets and splits.\n",
    "for file in dataset_list:\n",
    "    for split in split_list:\n",
    "\n",
    "        # Load data from specified sources.\n",
    "        pred_bbox_list, target_bbox_list, inc_len, model, binary_grouped = load_data(model_input, mode, file, split)\n",
    "\n",
    "        # If any of the data is not found, skip this iteration.\n",
    "        if pred_bbox_list == -1 or target_bbox_list == -1 or inc_len == -1:\n",
    "            pass\n",
    "        else:\n",
    "            print(file + split)\n",
    "            found_sets_list.append(file + split)  \n",
    "\n",
    "            #group the predicted coordinates, target coordinates and model information by sentence\n",
    "            pred_group = group_by_increment(pred_bbox_list, inc_len)\n",
    "            targ_group = group_by_increment(target_bbox_list, inc_len)\n",
    "            model_group = group_by_increment(model, inc_len)\n",
    "\n",
    "            # Split bounding boxes into categories (Right, Wrong, Mixed) \n",
    "            only_one, only_zero, mixed = split_by_correct(binary_grouped)\n",
    "\n",
    "            #calculate the covered area\n",
    "            if box_mode == \"pred\":\n",
    "                cov_area_one = covered_area(pred_group, only_one, model_group)\n",
    "                cov_area_zero = covered_area(pred_group, only_zero, model_group)\n",
    "                cov_area_mixed = covered_area(pred_group, mixed, model_group)\n",
    "            elif box_mode == \"targ\":\n",
    "                cov_area_one = covered_area(targ_group, only_one, model_group)\n",
    "                cov_area_zero = covered_area(targ_group, only_zero, model_group)\n",
    "                cov_area_mixed = covered_area(targ_group, mixed, model_group)\n",
    "            else:\n",
    "                print(\"Box Mode must be either pred or targ. It is:\", box_mode)\n",
    "                break  \n",
    "\n",
    "            cov_area_all = cov_area_one + cov_area_zero + cov_area_mixed\n",
    "\n",
    "            # Uncomment the following line to plot the distribution of coverage percentages.\n",
    "            # plot_dist(cov_area_all, file, split)\n",
    "\n",
    "            # Create a list of coverage areas for different categories and types.\n",
    "            cov_list = [cov_area_one, cov_area_zero, cov_area_mixed, cov_area_all]\n",
    "            cov_type = [\"Right\", \"Wrong\", \"Mixed\", \"All\"]\n",
    "\n",
    "            # Calculate average sizes and standard deviations for different categories.\n",
    "            for lst, type in zip(cov_list, cov_type):\n",
    "                lst = [item for sublist in lst for item in sublist]\n",
    "                lst = [tensor.tolist() for tensor in lst]\n",
    "\n",
    "                if type == \"Right\":\n",
    "                    one_sum.append(round(sum(lst) / len(lst), 2))\n",
    "                    one_std.append(round(statistics.stdev(lst), 2))\n",
    "                elif type == \"Wrong\":\n",
    "                    zero_sum.append(round(sum(lst) / len(lst), 2))\n",
    "                    zero_std.append(round(statistics.stdev(lst), 2))\n",
    "                elif type == \"Mixed\":\n",
    "                    mixed_sum.append(round(sum(lst) / len(lst), 2))\n",
    "                    mixed_std.append(round(statistics.stdev(lst), 2))\n",
    "                elif type == \"All\":\n",
    "                    all_sum.append(round(sum(lst) / len(lst), 2))\n",
    "                    all_std.append(round(statistics.stdev(lst), 2))\n",
    "\n",
    "\n",
    "data = {}\n",
    "data[model_input + \" \" + box_mode] = found_sets_list\n",
    "data[\"Right Avg Size\"] = one_sum\n",
    "#data[\"Right Standard Deviation\"] = one_std\n",
    "\n",
    "data[\"Wrong Avg Size\"] = zero_sum\n",
    "#data[\"Wrong Standard Deviation\"] = zero_std\n",
    "\n",
    "data[\"Mixed Avg Size\"] = mixed_sum\n",
    "#data[\"Mixed Standard Deviation\"] = mixed_std\n",
    "\n",
    "data[\"All Avg Size\"] = all_sum\n",
    "#data[\"All Standard Deviation\"] = all_std\n",
    "\n",
    "# Create a DataFrame using the data dictionary and set the index.\n",
    "df = pd.DataFrame(data)\n",
    "df.set_index(model_input + \" \" + box_mode, inplace=True)\n",
    "\n",
    "# Display the DataFrame.\n",
    "df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "simrec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
